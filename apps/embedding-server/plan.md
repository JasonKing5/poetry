可用于中文搜索 / 语义检索 / 古诗词向量化的模型，对比说明。内容涵盖：性能、使用场景、推荐硬件、是否支持古文等维度。

⸻

📊 中文语义搜索模型对比表（适合古诗词等中文语义检索）

| 模型名称 |  维度 |  体积 |  模型特色 |  推荐场景 |  推荐硬件 |  是否支持古诗词 |  优劣势 |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| BAAI/bge-small-zh |  384 ~45MB |  高性能中文语义模型，开箱即用，支持 pooling 和检索优化 |  文本向量检索、问答匹配、搜索推荐 |  CPU / 任意机器 |  ✅ 支持（效果尚可） |  ✅ 轻量 ✅ 速度快 ❗较长文/诗句效果一般 |
| BAAI/bge-large-zh |  1024 ~330MB |  精度更高但更大，适合高质量向量检索 |  问答、文档搜索、向量召回 |  ✅ 推荐 GPU（但 CPU 也可跑） |  ✅ 更适合古文语义表达 |  ✅ 准确率高 ❗慢 ❗内存占用大 |
| shibing624/text2vec-base-multilingual |  768 ~400MB |  多语言支持，基于 sentence-transformers 的中文优化模型 |  多语言检索、文本相似度 |  CPU / GPU |  ✅ 支持古文（但泛化） |  ✅ 兼容性强 ❗性能略低 |
| uer/sbert-base-chinese-nli |  768 ~110MB |  中文 NLI 语义模型，适合句子相似度对比 |  相似句子匹配 |  CPU 即可 |  ✅ 一般 |  ❗适配性一般，优化不如 bge |
| moka-ai/m3e-small |  512 ~100MB |  支持中文、拼音、英文混合语义表达，适合复杂搜索场景 |  中文搜索、代码搜索、FAQ 匹配 |  CPU / GPU |  ✅ 支持拼音搜索、古文较好 |  ✅ 多模态泛化好 ❗需稍调参 |
| Langboat/mengzi-bert-base |  768 ~420MB |  中文泛领域语义理解模型（含文言文） |  法律、金融、古文语料 |  GPU 推荐 |  ✅ 古诗词表现较好 |  ✅ 语料丰富 ❗速度慢 ❗无 pooling 封装 |


⸻

✅ 推荐建议（本地机器运行支持中文古诗词搜索的应用场景）

「中文搜索 + 古诗词语义匹配」，推荐如下：

| 需求 | 推荐模型 | 理由 |
| ---- | ---- | ---- |
| 实时搜索，快速响应 | BAAI/bge-small-zh | ✅ 响应快、内存占用小 |
| 追求更准匹配、更懂古文 | BAAI/bge-large-zh / moka-ai/m3e-small | 精度更高，更适合做“古诗词相似内容召回” |
| 支持拼音、错别字检索 | m3e-small | 支持中文+拼音混合检索，适配性强 |
| 批量训练/微调 | bge or m3e + 自建检索库 | 支持向量召回 + rerank 效果佳 |


⸻

⚙️ 推荐硬件配置

| 使用方式 | 推荐配置 |
| ---- | ---- |
| 本地开发 | MacBook / 笔记本 CPU 即可（small 模型） |
| 小型服务部署 | 2C4G+（CPU 即可跑 bge-small） |
| 高性能搜索服务 | GPU (如 T4, A10) + Faiss/pgvector |
| 高 QPS 推理 | 多线程服务 + ONNX 模型加速 |


⸻

🔍 古诗词搜索需要注意

| 问题 | 说明 |
| ---- | ---- |
| 文体短、含典故 | 普通中文 embedding 对典故/意境理解有限 |
| 推荐做法 | 使用 bge/m3e 先召回，再 rerank（可用 bge-reranker） |
| 加分技巧 | 使用标题 + 作者 + 正文联合生成向量；可加拼音字段；构建同义词表 |
